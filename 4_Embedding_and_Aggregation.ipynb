{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Student Vectors (Embedding + Aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook generate students vector in \"course\" with CodeBook k (k:the number of centroids, 100 is default)\n",
    "\".\\data\\vectors\\norm_Student_Vctors_course{course}_{k}dim.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext as ft\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select courses and k (the number of centroids). k correspond to the dimensions of student vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# course_list = [A-2021,A-2022,D-2021,D-2022]\n",
    "course= \"A-2022\"\n",
    "k=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code_Book_dir = r\".\\data\\code_book\"\n",
    "CodeBook_file = Code_Book_dir + r\"\\CodeBook_k{}.csv\".format(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepareing for Generating Student vectors in \"course\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions :  All actions in one course \n",
    "# user_df :  userid and actions of this student\n",
    "\n",
    "actions = r\".\\data2\\actions_txt\\actions_{}_perStudents.txt\".format(course)\n",
    "users_actions = []\n",
    "user_action = \"\"\n",
    "user=[]\n",
    "with open(actions, \"r\") as f:\n",
    "    actions_list = f.readlines()\n",
    "    for action in actions_list:\n",
    "        if action.startswith(\"****\"):\n",
    "            user.append(action.rstrip(\"\\n\").replace(\"*\",\"\"))\n",
    "            users_actions.append(user_action)\n",
    "            user_action = \"\"\n",
    "        else:\n",
    "            user_action += action + \" \"\n",
    "user_df = pd.DataFrame(users_actions)\n",
    "user_df[\"userid\"] = user\n",
    "user_df.set_index(\"userid\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read CodeBook\n",
    "\n",
    "action_centroids = pd.read_csv(CodeBook_file,index_col=0)\n",
    "## load fastText model (we must use the same model to Making CodeBook)\n",
    "model = ft.load_model(r\".\\model\\fastText_trainALL-2020_100dim_30epoch.bin\")\n",
    "\n",
    "### Aggregation step\n",
    "# users_vecs: output students vector \n",
    "users_vecs =[]\n",
    "# users actions\n",
    "users_data = user_df.values\n",
    "# aggregation step for one student\n",
    "for actions_one_user in users_data:\n",
    "        # user_vec = one student aggregated vector \n",
    "        user_vec = [0*i for i in range(len(action_centroids))]\n",
    "        # split each actions \n",
    "        actions_oneuser = actions_one_user[0].split(\"\\n\") \n",
    "        for one_action in actions_oneuser:\n",
    "            # if empty action, skip vectorization\n",
    "            if one_action == \"\" or one_action == \" \":\n",
    "                    continue\n",
    "            # vector of action generated by fastText\n",
    "            # embedding\n",
    "            one_action_vec = model.get_sentence_vector(one_action)\n",
    "            # calculate cosine similarity between action vec and centroids\n",
    "            sim_mat = cosine_similarity(one_action_vec.reshape(1,-1), action_centroids.values)\n",
    "            # get the most similar centroids ID\n",
    "            max_index = np.argmax(sim_mat)\n",
    "            # count the most similar centroids \n",
    "            user_vec[max_index] += 1\n",
    "        users_vecs.append(user_vec)\n",
    "boa_df = pd.DataFrame(users_vecs,index=user_df.index)\n",
    "\n",
    "#normarization\n",
    "norm_boa_df = pd.DataFrame(normalize(boa_df,norm=\"l2\",axis=1),index=boa_df.index)\n",
    "norm_boa_df.to_csv(r\".\\data2\\vectors\\norm_Student_Vctors_course{}_{}dim.csv\".format(course,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_boa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To comparsion, fasttext trained by A-2020, and D-2020. k = 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read CodeBook\n",
    "if k == 100:\n",
    "        CodeBook_file = Code_Book_dir + r\"\\CodeBook_k{}_A20.csv\".format(k)\n",
    "        action_centroids = pd.read_csv(CodeBook_file,index_col=0)\n",
    "        ## load fastText model (we must use the same model to Making CodeBook)\n",
    "        model = ft.load_model(r\".\\model\\fastText_trainA-2020_100dim_30epoch.bin\")\n",
    "\n",
    "        ### Aggregation step\n",
    "        # users_vecs: output students vector \n",
    "        users_vecs =[]\n",
    "        # users actions\n",
    "        users_data = user_df.values\n",
    "        # aggregation step for one student\n",
    "        for actions_one_user in users_data:\n",
    "                # user_vec = one student aggregated vector \n",
    "                user_vec = [0*i for i in range(len(action_centroids))]\n",
    "                # split each actions \n",
    "                actions_oneuser = actions_one_user[0].split(\"\\n\") \n",
    "                for one_action in actions_oneuser:\n",
    "                # if empty action, skip vectorization\n",
    "                        if one_action == \"\" or one_action == \" \":\n",
    "                                continue\n",
    "                        # vector of action generated by fastText\n",
    "                        # embedding\n",
    "                        one_action_vec = model.get_sentence_vector(one_action)\n",
    "                        # calculate cosine similarity between action vec and centroids\n",
    "                        sim_mat = cosine_similarity(one_action_vec.reshape(1,-1), action_centroids.values)\n",
    "                        # get the most similar centroids ID\n",
    "                        max_index = np.argmax(sim_mat)\n",
    "                        # count the most similar centroids \n",
    "                        user_vec[max_index] += 1\n",
    "                users_vecs.append(user_vec)\n",
    "        boa_df = pd.DataFrame(users_vecs,index=user_df.index)\n",
    "\n",
    "        #normarization\n",
    "        norm_boa_df = pd.DataFrame(normalize(boa_df,norm=\"l2\",axis=1),index=boa_df.index)\n",
    "        norm_boa_df.to_csv(r\".\\data2\\vectors\\norm_Student_Vctors_course{}_{}dim_A20.csv\".format(course,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_boa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read CodeBook\n",
    "if k==100:\n",
    "        CodeBook_file = Code_Book_dir + r\"\\CodeBook_k{}_D20.csv\".format(k)\n",
    "        action_centroids = pd.read_csv(CodeBook_file,index_col=0)\n",
    "        ## load fastText model (we must use the same model to Making CodeBook)\n",
    "        model = ft.load_model(r\".\\model\\fastText_trainD-2020_100dim_30epoch.bin\")\n",
    "\n",
    "        ### Aggregation step\n",
    "        # users_vecs: output students vector \n",
    "        users_vecs =[]\n",
    "        # users actions\n",
    "        users_data = user_df.values\n",
    "        # aggregation step for one student\n",
    "        for actions_one_user in users_data:\n",
    "                # user_vec = one student aggregated vector \n",
    "                user_vec = [0*i for i in range(len(action_centroids))]\n",
    "                # split each actions \n",
    "                actions_oneuser = actions_one_user[0].split(\"\\n\") \n",
    "                for one_action in actions_oneuser:\n",
    "                # if empty action, skip vectorization\n",
    "                        if one_action == \"\" or one_action == \" \":\n",
    "                                continue\n",
    "                        # vector of action generated by fastText\n",
    "                        # embedding\n",
    "                        one_action_vec = model.get_sentence_vector(one_action)\n",
    "                        # calculate cosine similarity between action vec and centroids\n",
    "                        sim_mat = cosine_similarity(one_action_vec.reshape(1,-1), action_centroids.values)\n",
    "                        # get the most similar centroids ID\n",
    "                        max_index = np.argmax(sim_mat)\n",
    "                        # count the most similar centroids \n",
    "                        user_vec[max_index] += 1\n",
    "                users_vecs.append(user_vec)\n",
    "        boa_df = pd.DataFrame(users_vecs,index=user_df.index)\n",
    "\n",
    "        #normarization\n",
    "        norm_boa_df = pd.DataFrame(normalize(boa_df,norm=\"l2\",axis=1),index=boa_df.index)\n",
    "        norm_boa_df.to_csv(r\".\\data2\\vectors\\norm_Student_Vctors_course{}_{}dim_D20.csv\".format(course,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_boa_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
